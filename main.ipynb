{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5VS7pFj-1Lo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3lOpJy9A3Gw"
      },
      "outputs": [],
      "source": [
        "!pip install pgmpy\n",
        "!pip install tqdm\n",
        "!pip install networkx matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW5vBXCu-Ezp"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "project_path = '/content/drive/My Drive/ICON'\n",
        "src_path = os.path.join(project_path, 'src')\n",
        "\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "try:\n",
        "    os.chdir(project_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"cartella non trovata\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DzheeTb_BVJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from loader_dati import carica_e_pulisci_base, riempimento_dati\n",
        "from eda import esegui_eda_base, traccia_distribuzioni\n",
        "from preprocessing import preprocessa_dati\n",
        "from clustering import trova_k_ottimale, applica_kmeans_e_aggiungi_feature\n",
        "from modelli import ottieni_modelli, ottieni_griglie_parametri\n",
        "from valutazioni import ottimizza_e_valuta_modelli_cv, stampa_risultati_cv\n",
        "from rete_bayesiana import valuta_rete_bayesiana\n",
        "\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCqn3Z0c_XIP"
      },
      "outputs": [],
      "source": [
        "PERCORSO_FILE_CSV = 'dataset/heart-disease/heart_disease_uci.csv'\n",
        "COLONNA_TARGET = 'target'\n",
        "NUM_SPLIT_ESTERNI = 10\n",
        "NUM_SPLIT_INTERNI = 5\n",
        "MAX_K_CLUSTERING = 8\n",
        "STATO_CASUALE = 42\n",
        "K_OTTIMALE = 4 #da verificare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opDOdiap_8J-"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_dati_con_nan = carica_e_pulisci_base(PERCORSO_FILE_CSV)\n",
        "df_dati_riempiti = riempimento_dati(df_dati_con_nan.copy() if df_dati_con_nan is not None else None)\n",
        "if df_dati_riempiti is not None:\n",
        "    print(\"\\nload ok\")\n",
        "    print(\"\\ndati nan:\")\n",
        "    print(df_dati_con_nan.head())\n",
        "    print(\"\\ndati riempiti:\")\n",
        "    print(df_dati_riempiti.head())\n",
        "    print(f\"\\nnan nei riempiti: {df_dati_riempiti.isnull().sum().sum()}\")\n",
        "else:\n",
        "    print(\"loead e pulizia falliti.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQAcYzmgA1J9"
      },
      "outputs": [],
      "source": [
        "if df_dati_riempiti is not None:\n",
        "    esegui_eda_base(df_dati_riempiti)\n",
        "    traccia_distribuzioni(df_dati_riempiti)\n",
        "else:\n",
        "    print(\"load fallito\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cVvT148qGQ8"
      },
      "outputs": [],
      "source": [
        " #preprocessing Iniziale (no cluster)\n",
        "X_proc_no_cluster, y_target, preprocessore_no_cluster, nomi_feature_no_cluster = None, None, None, None\n",
        "if df_dati_riempiti is not None:\n",
        "    X_proc_no_cluster, y_target, preprocessore_no_cluster, nomi_feature_no_cluster = preprocessa_dati(df_dati_riempiti.copy(), COLONNA_TARGET)\n",
        "else:\n",
        "    print(\"errore caricamento, preprocessing saltato\")\n",
        "\n",
        "\n",
        "if X_proc_no_cluster is not None:\n",
        "    try:\n",
        "        print(\"\\nprime righe dati processati (senza cluster):\")\n",
        "        print(pd.DataFrame(X_proc_no_cluster, columns=nomi_feature_no_cluster).head())\n",
        "    except ValueError:\n",
        "         print(\"impossibile mostrare dataframe preprocessato.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrpA-Htu5ToY"
      },
      "outputs": [],
      "source": [
        "# Per trovare il K ottimale\n",
        "if X_proc_no_cluster is not None:\n",
        "    trova_k_ottimale(X_proc_no_cluster, max_k=MAX_K_CLUSTERING, stato_casuale=STATO_CASUALE)\n",
        "else:\n",
        "    print(\"clustering saltato errore preprocessing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1aoCAV38J_r"
      },
      "outputs": [],
      "source": [
        "# applicazione k-means e feature con cluster\n",
        "X_proc_con_cluster, preprocessore_con_cluster, nomi_feature_con_cluster = None, None, None\n",
        "if X_proc_no_cluster is not None and df_dati_riempiti is not None:\n",
        "    X_proc_con_cluster, preprocessore_con_cluster, nomi_feature_con_cluster, etichette_cluster = applica_kmeans_e_aggiungi_feature(\n",
        "    df_dati_riempiti.drop(COLONNA_TARGET, axis=1),\n",
        "    X_proc_no_cluster,\n",
        "    K_OTTIMALE,\n",
        "    stato_casuale=STATO_CASUALE\n",
        ")\n",
        "if df_dati_riempiti is not None and etichette_cluster is not None:\n",
        "     df_dati_con_cluster = df_dati_riempiti.copy()\n",
        "     df_dati_con_cluster['cluster'] = etichette_cluster\n",
        "     print(\"\\nDataFrame originale con etichette cluster aggiunto:\")\n",
        "     print(df_dati_con_cluster[['target', 'cluster']].head())\n",
        "else:\n",
        "    print(\"feature cluster saltata.\")\n",
        "\n",
        "if X_proc_con_cluster is not None:\n",
        "    try:\n",
        "        print(\"\\nrighe dati processati (cluster):\")\n",
        "        print(pd.DataFrame(X_proc_con_cluster, columns=nomi_feature_con_cluster).head())\n",
        "    except ValueError:\n",
        "        print(\"impossibile mostrare dataframe con cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFYxGG7CXiR6"
      },
      "outputs": [],
      "source": [
        "#analisi cluster\n",
        "if 'df_dati_con_cluster' in locals() and df_dati_con_cluster is not None:\n",
        "    colonne_numeriche_originali = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
        "    colonne_categoriche_originali = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "    print(\"\\nmedie feature numeriche per cluster:\")\n",
        "    medie_cluster = df_dati_con_cluster.groupby('cluster')[colonne_numeriche_originali].mean()\n",
        "    print(medie_cluster)\n",
        "    print(\"\\nmoda feature categoriche cluster:\")\n",
        "    for col in colonne_categoriche_originali:\n",
        "        if col in df_dati_con_cluster.columns:\n",
        "             print(f\"\\ndistribuzione '{col}' per cluster:\")\n",
        "             freq_rel = df_dati_con_cluster.groupby('cluster')[col].value_counts(normalize=True).unstack(fill_value=0) * 100\n",
        "             print(freq_rel.round(1).to_string())\n",
        "\n",
        "    print(\"\\ndistribuzione target per cluster\")\n",
        "    print((df_dati_con_cluster.groupby('cluster')['target'].value_counts(normalize=True).unstack(fill_value=0) * 100).round(1))\n",
        "\n",
        "else:\n",
        "    print(\"dataframe non disponibile per l'analisi.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LMYNZ7PC1kc"
      },
      "outputs": [],
      "source": [
        "#modelli e grid\n",
        "tutti_i_modelli = ottieni_modelli(stato_casuale=STATO_CASUALE)\n",
        "griglie_parametri = ottieni_griglie_parametri()\n",
        "\n",
        "modelli_standard = tutti_i_modelli\n",
        "griglie_standard = griglie_parametri\n",
        "\n",
        "print(\"Modelli e griglie definiti (senza Naive Bayes).\")\n",
        "print(\"Modelli Standard:\", list(modelli_standard.keys()))\n",
        "print(\"Griglie Standard:\", griglie_standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QomHqV_OE5Qi"
      },
      "outputs": [],
      "source": [
        "#valutazione rete bayesiana\n",
        "risultati_bn_dict = None\n",
        "if 'df_dati_riempiti' in locals() and df_dati_riempiti is not None:\n",
        "    try:\n",
        "        print(\"valutazione rete bayesiana\")\n",
        "        risultati_bn_dict, _ = valuta_rete_bayesiana(\n",
        "            df_dati_riempiti.copy(),\n",
        "            target_col=COLONNA_TARGET,\n",
        "            num_split=3,  # Usa 3 fold per velocit√†\n",
        "            stato_casuale=STATO_CASUALE,\n",
        "            plot_miglior_struttura=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"errore: {e}\")\n",
        "        metriche = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "        risultati_bn_dict = {\n",
        "            'rete bayesiana': {\n",
        "                'scores': {f'test_{m}': np.array([np.nan] * 3) for m in metriche}\n",
        "            }\n",
        "        }\n",
        "else:\n",
        "    print(\"valutazione saltata\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3PO5v9RSApT"
      },
      "outputs": [],
      "source": [
        "#valutazione modelli normali senza cluster\n",
        "print(\"valutazione modelli normali senza cluster\")\n",
        "risultati_no_cluster = None\n",
        "if X_proc_no_cluster is not None and y_target is not None:\n",
        "    risultati_no_cluster = ottimizza_e_valuta_modelli_cv(\n",
        "        modelli_standard, griglie_standard, X_proc_no_cluster, y_target,\n",
        "        num_split_esterni=NUM_SPLIT_ESTERNI, num_split_interni=NUM_SPLIT_INTERNI, stato_casuale=STATO_CASUALE\n",
        "    )\n",
        "else:\n",
        "    print(\"valutazione modelli normali senza cluster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_EFSBgySYde"
      },
      "outputs": [],
      "source": [
        "#valutazione modelli normali con cluster\n",
        "print(\"valutazione modelli normali con cluster\")\n",
        "risultati_con_cluster = None\n",
        "if X_proc_con_cluster is not None and y_target is not None:\n",
        "\n",
        "    modelli_standard_clust = ottieni_modelli(stato_casuale=STATO_CASUALE)\n",
        "    modelli_standard_clust = {nome: modello for nome, modello in modelli_standard_clust.items() if nome != 'Naive Bayes'}\n",
        "\n",
        "    risultati_con_cluster = ottimizza_e_valuta_modelli_cv(\n",
        "        modelli_standard_clust, griglie_standard, X_proc_con_cluster, y_target,\n",
        "        num_split_esterni=NUM_SPLIT_ESTERNI, num_split_interni=NUM_SPLIT_INTERNI, stato_casuale=STATO_CASUALE\n",
        "    )\n",
        "else:\n",
        "    print(\"valutazione modelli normali con cluster saltata\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1TYa9X2VDcy"
      },
      "outputs": [],
      "source": [
        "#riepilogo risultati\n",
        "print(\"riepilogo risultati\")\n",
        "risultati_finali_combinati = {}\n",
        "\n",
        "def aggiungi_parametri_mancanti(risultati_dict):\n",
        "    for nome, dati in risultati_dict.items():\n",
        "        if dati and 'best_params_per_fold' not in dati:\n",
        "            if 'scores' in dati and dati['scores']:\n",
        "                first_metric_key = next(iter(dati['scores'].keys()))\n",
        "                num_folds = len(dati['scores'][first_metric_key])\n",
        "                dati['best_params_per_fold'] = [\"N/A\"] * num_folds\n",
        "    return risultati_dict\n",
        "\n",
        "if 'risultati_bn_dict' in locals() and risultati_bn_dict:\n",
        "    risultati_bn_dict_corretto = aggiungi_parametri_mancanti(risultati_bn_dict)\n",
        "    risultati_finali_combinati.update(risultati_bn_dict_corretto)\n",
        "\n",
        "if 'risultati_no_cluster' in locals() and risultati_no_cluster:\n",
        "    risultati_no_cluster_corretto = aggiungi_parametri_mancanti(risultati_no_cluster)\n",
        "    risultati_finali_combinati.update(risultati_no_cluster_corretto)\n",
        "\n",
        "if 'risultati_con_cluster' in locals() and risultati_con_cluster:\n",
        "    risultati_con_cluster_corretto = aggiungi_parametri_mancanti(risultati_con_cluster)\n",
        "    for nome_modello, dati_ris in risultati_con_cluster_corretto.items():\n",
        "        nome_nuovo = nome_modello.replace(\" (tuned)\", \" + clust (tuned)\") if \" (tuned)\" in nome_modello else nome_modello + \" + clust\"\n",
        "        risultati_finali_combinati[nome_nuovo] = dati_ris\n",
        "\n",
        "if risultati_finali_combinati:\n",
        "    print(f\"modelli: {list(risultati_finali_combinati.keys())}\")\n",
        "    df_risultati_finali = stampa_risultati_cv(risultati_finali_combinati)\n",
        "\n",
        "    try:\n",
        "        df_risultati_finali.to_csv('risultati_finali_comparazione_modelli.csv')\n",
        "        print(\"\\nrisultati salvati\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nrisultati non salvati: {e}\")\n",
        "else:\n",
        "    print(\"nessun riepilogo\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}